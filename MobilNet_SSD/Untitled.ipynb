{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--video VIDEO] [--prototxt PROTOTXT]\n",
      "                             [--weights WEIGHTS] [--thr THR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-5489ac8c-6f90-4013-b53a-052e6f357e25.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#Import the neccesary libraries\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 \n",
    "\n",
    "# construct the argument parse \n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Script to run MobileNet-SSD object detection network ')\n",
    "parser.add_argument(\"--video\", help=\"motor_bike.mp4\")\n",
    "parser.add_argument(\"--prototxt\", default=\"MobileNetSSD_deploy.prototxt\",\n",
    "                                  help='Path to text network file: '\n",
    "                                       'MobileNetSSD_deploy.prototxt for Caffe model or '\n",
    "                                       )\n",
    "parser.add_argument(\"--weights\", default=\"MobileNetSSD_deploy.caffemodel\",\n",
    "                                 help='Path to weights: '\n",
    "                                      'MobileNetSSD_deploy.caffemodel for Caffe model or '\n",
    "                                      )\n",
    "parser.add_argument(\"--thr\", default=0.2, type=float, help=\"confidence threshold to filter out weak detections\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Labels of Network.\n",
    "classNames = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }\n",
    "\n",
    "# Open video file or capture device. \n",
    "if args.video:\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(\"motor_bike.mp4\")\n",
    "\n",
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe(args.prototxt, args.weights)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_resized = cv2.resize(frame,(300,300)) # resize frame for prediction\n",
    "\n",
    "    # MobileNet requires fixed dimensions for input image(s)\n",
    "    # so we have to ensure that it is resized to 300x300 pixels.\n",
    "    # set a scale factor to image because network the objects has differents size. \n",
    "    # We perform a mean subtraction (127.5, 127.5, 127.5) to normalize the input;\n",
    "    # after executing this command our \"blob\" now has the shape:\n",
    "    # (1, 3, 300, 300)\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "    #Set to network the input blob \n",
    "    net.setInput(blob)\n",
    "    #Prediction of network\n",
    "    detections = net.forward()\n",
    "\n",
    "    #Size of frame resize (300x300)\n",
    "    cols = frame_resized.shape[1] \n",
    "    rows = frame_resized.shape[0]\n",
    "\n",
    "    #For get the class and location of object detected, \n",
    "    # There is a fix index for class, location and confidence\n",
    "    # value in @detections array .\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] #Confidence of prediction \n",
    "        if confidence > args.thr: # Filter prediction \n",
    "            class_id = int(detections[0, 0, i, 1]) # Class label\n",
    "\n",
    "            # Object location \n",
    "            xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "            yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "            xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "            yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "            \n",
    "            # Factor for scale to original size of frame\n",
    "            heightFactor = frame.shape[0]/300.0  \n",
    "            widthFactor = frame.shape[1]/300.0 \n",
    "            # Scale object detection to frame\n",
    "            xLeftBottom = int(widthFactor * xLeftBottom) \n",
    "            yLeftBottom = int(heightFactor * yLeftBottom)\n",
    "            xRightTop   = int(widthFactor * xRightTop)\n",
    "            yRightTop   = int(heightFactor * yRightTop)\n",
    "            # Draw location of object  \n",
    "            cv2.rectangle(frame, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),\n",
    "                          (0, 255, 0))\n",
    "\n",
    "            # Draw label and confidence of prediction in frame resized\n",
    "            if class_id in classNames:\n",
    "                label = classNames[class_id] + \": \" + str(confidence)\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "                yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "                cv2.rectangle(frame, (xLeftBottom, yLeftBottom - labelSize[1]),\n",
    "                                     (xLeftBottom + labelSize[0], yLeftBottom + baseLine),\n",
    "                                     (255, 255, 255), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (xLeftBottom, yLeftBottom),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "                print(label) #print class and confidence\n",
    "\n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) >= 0:  # Break with ESC \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
